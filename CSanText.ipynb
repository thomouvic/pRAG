{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics.pairwise import manhattan_distances\n",
    "from scipy.spatial.distance import cityblock\n",
    "from scipy.spatial.distance import pdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding dimension: 300\n"
     ]
    }
   ],
   "source": [
    "def load_glove_embeddings(glove_file_path='glove.6B.300d.txt'):\n",
    "    embeddings = {}\n",
    "    with open(glove_file_path, 'r', encoding='utf-8') as f:\n",
    "        first_line = f.readline().strip()\n",
    "        # Find the index of the first numerical token\n",
    "        embedding_start_index = None\n",
    "        for i, token in enumerate(first_line.split()):\n",
    "            try:\n",
    "                float(token)  # Attempt to convert the token to a float\n",
    "                embedding_start_index = i\n",
    "                break\n",
    "            except ValueError:\n",
    "                continue\n",
    "        if embedding_start_index is None:\n",
    "            raise ValueError(\"Could not determine the start of the embedding vector in the first line.\")\n",
    "        \n",
    "        embedding_dim = len(first_line.split()) - embedding_start_index  # Determine the embedding dimension\n",
    "        print(f\"Embedding dimension: {embedding_dim}\")\n",
    "        \n",
    "        # Reset the file pointer to the beginning of the file\n",
    "        f.seek(0)\n",
    "        for line in f:\n",
    "            values = line.strip().split()\n",
    "            word = ' '.join(values[:-embedding_dim])  # Reconstruct the word\n",
    "            vector = list(map(float, values[-embedding_dim:]))  # Extract the embedding vector\n",
    "            embeddings[word] = vector\n",
    "\n",
    "    return embeddings\n",
    "\n",
    "# Load the embeddings\n",
    "embeddings = load_glove_embeddings(glove_file_path='embeddings_countries.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('åland islands', -0.0), ('faroe islands', -49.706144089999995), ('cayman islands', -56.54005485), ('solomon islands', -59.75879071), ('marshall islands', -61.417534605), ('northern mariana islands', -63.68305945166667), ('cocos (keeling) islands', -66.449814969), ('cook islands', -66.69857771), ('turks and caicos islands', -67.32165119500002), ('falkland islands (malvinas)', -67.854533625), ('virgin islands (british)', -68.38514268166668), ('heard island and mcdonald islands', -70.663665195), ('virgin islands (u.s.)', -71.39904455266667), ('united states minor outlying islands', -73.85662849299999), ('south georgia and the south sandwich islands', -81.29605458071428), ('bouvet island', -81.565424485), ('norfolk island', -82.820635275), ('antigua and barbuda', -83.66415023833332), ('christmas island', -83.969834265), ('british indian ocean territory', -84.5136254225)]\n",
      "[('bangladesh', -0.0), ('pakistan', -86.06863594000001), ('sri lanka', -86.60521655), ('india', -89.79430434), ('nepal', -91.34529721), ('maldives', -93.55023359), ('zimbabwe', -97.31725756), ('british indian ocean territory', -98.3237130775), ('united kingdom of great britain and northern ireland', -98.77946297874999), ('trinidad and tobago', -99.77603080666667), ('south georgia and the south sandwich islands', -99.82501313714286), ('papua new guinea', -100.22406082666667), ('taiwan, province of china', -100.56583472333332), ('namibia', -101.23105521), ('tanzania, united republic of', -101.29523357333333), ('moldova (republic of)', -101.40594642), ('congo (republic of the)', -101.4418627325), ('malaysia', -101.47332739000001), ('central african republic', -101.52576651666666), ('bolivia (plurinational state of)', -101.88289289875001)]\n"
     ]
    }
   ],
   "source": [
    "# This code is not strictly necessary, but it only serves to see if the embeddings make sense\n",
    "\n",
    "def get_top_similarities(target_word, embeddings, top_n=20):\n",
    "    target_embedding = embeddings.get(target_word)\n",
    "    if target_embedding is None:\n",
    "        return None\n",
    "\n",
    "    similarities = {}\n",
    "    for word, word_embedding in embeddings.items():\n",
    "        similarities[word] = -cityblock(target_embedding, word_embedding)\n",
    "\n",
    "    sorted_similarities = sorted(similarities.items(), key=lambda x: x[1], reverse=True)\n",
    "    return sorted_similarities[:top_n]\n",
    "\n",
    "\n",
    "\n",
    "# example usage\n",
    "top_20_similarities = get_top_similarities('åland islands', embeddings)\n",
    "print(top_20_similarities)\n",
    "\n",
    "top_20_similarities = get_top_similarities('bangladesh', embeddings)\n",
    "print(top_20_similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0: antarctica, greenland\n",
      "Cluster 1: andorra, anguilla, antigua and barbuda, aruba, bahamas, barbados, belize, bonaire, sint eustatius and saba, costa rica, curaçao, el salvador, grenada, guadeloupe, guatemala, haiti, honduras, jamaica, martinique, montserrat, nicaragua, panama, puerto rico, saint barthélemy, saint kitts and nevis, saint lucia, trinidad and tobago\n",
      "Cluster 2: bhutan, dominica, fiji, guyana, kiribati, maldives, mayotte, nauru, niue, palau, réunion, samoa, suriname, timor-leste, tokelau, tonga, tuvalu, vanuatu\n",
      "Cluster 3: bahrain, egypt, iran, iraq, israel, jordan, kuwait, lebanon, libya, morocco, oman, qatar, saudi arabia, syrian arab republic, united arab emirates, yemen\n",
      "Cluster 4: armenia, azerbaijan, belarus, georgia, kazakhstan, kyrgyzstan, tajikistan, turkey, turkmenistan, ukraine, uzbekistan\n",
      "Cluster 5: australia, bangladesh, india, malaysia, nepal, pakistan, sri lanka\n",
      "Cluster 6: afghanistan, bolivia (plurinational state of), brazil, brunei darussalam, cambodia, canada, central african republic, china, colombia, congo (republic of the), congo (democratic republic of the), cuba, french southern territories, vatican city state, hong kong, indonesia, japan, korea (democratic people's republic of), korea (republic of), lao people's democratic republic, macao, macedonia (the former yugoslav republic of), mexico, mongolia, myanmar, palestine, state of, peru, philippines, russian federation, singapore, south africa, south sudan, taiwan, province of china, tanzania, united republic of, thailand, united kingdom of great britain and northern ireland, united states of america, venezuela (bolivarian republic of), vietnam, western sahara\n",
      "Cluster 7: algeria, benin, burkina faso, cabo verde, cameroon, chad, comoros, côte d'ivoire, djibouti, equatorial guinea, eritrea, gabon, gambia, ghana, guinea, guinea-bissau, liberia, madagascar, mali, mauritania, mauritius, niger, sao tome and principe, senegal, seychelles, sierra leone, somalia, togo, tunisia\n",
      "Cluster 8: angola, botswana, burundi, ethiopia, kenya, lesotho, malawi, mozambique, namibia, nigeria, rwanda, sudan, swaziland, uganda, zambia, zimbabwe\n",
      "Cluster 9: guernsey, jersey\n",
      "Cluster 10: åland islands, american samoa, bermuda, bouvet island, british indian ocean territory, cayman islands, christmas island, cocos (keeling) islands, cook islands, falkland islands (malvinas), faroe islands, french guiana, french polynesia, gibraltar, guam, heard island and mcdonald islands, isle of man, marshall islands, micronesia (federated states of), monaco, new caledonia, new zealand, norfolk island, northern mariana islands, papua new guinea, pitcairn, saint helena, ascension and tristan da cunha, saint martin (french part), saint pierre and miquelon, saint vincent and the grenadines, san marino, sint maarten (dutch part), solomon islands, south georgia and the south sandwich islands, svalbard and jan mayen, turks and caicos islands, united states minor outlying islands, virgin islands (british), virgin islands (u.s.), wallis and futuna\n",
      "Cluster 11: argentina, austria, belgium, chile, france, germany, ireland, italy, luxembourg, netherlands, portugal, spain, switzerland\n",
      "Cluster 12: albania, bosnia and herzegovina, bulgaria, croatia, cyprus, czech republic, denmark, dominican republic, ecuador, estonia, finland, greece, hungary, iceland, latvia, liechtenstein, lithuania, malta, moldova (republic of), montenegro, norway, paraguay, poland, romania, serbia, slovakia, slovenia, sweden, uruguay\n"
     ]
    }
   ],
   "source": [
    "def bisecting_kmeans(embeddings, num_clusters):\n",
    "    # Initialize with all data in one cluster\n",
    "    clusters = {0: list(embeddings.keys())}\n",
    "    current_num_clusters = 1\n",
    "\n",
    "    while current_num_clusters < num_clusters:\n",
    "        # Find the largest cluster to split\n",
    "        largest_cluster_label = max(clusters, key=lambda label: len(clusters[label]))\n",
    "        largest_cluster = clusters.pop(largest_cluster_label)\n",
    "\n",
    "        # Extract embeddings for the largest cluster\n",
    "        largest_cluster_embeddings = [embeddings[word] for word in largest_cluster]\n",
    "\n",
    "        # Perform K-means with K=2 on the largest cluster\n",
    "        kmeans = KMeans(n_clusters=2, random_state=42)\n",
    "        kmeans.fit(largest_cluster_embeddings)\n",
    "\n",
    "        # Split the cluster into two new clusters\n",
    "        new_cluster_1 = [largest_cluster[i] for i, label in enumerate(kmeans.labels_) if label == 0]\n",
    "        new_cluster_2 = [largest_cluster[i] for i, label in enumerate(kmeans.labels_) if label == 1]\n",
    "\n",
    "        # Add the new clusters to the clusters dictionary\n",
    "        clusters[current_num_clusters] = new_cluster_1\n",
    "        clusters[current_num_clusters + 1] = new_cluster_2\n",
    "\n",
    "        # Update the number of clusters\n",
    "        current_num_clusters += 2\n",
    "\n",
    "    # Reassign cluster labels to be continuous from 0 to num_clusters - 1\n",
    "    new_clusters = {i: clusters[label] for i, label in enumerate(sorted(clusters.keys()))}\n",
    "\n",
    "    return new_clusters\n",
    "\n",
    "# Example usage\n",
    "\n",
    "number_of_words = len(embeddings.keys())\n",
    "avg_words_per_cluster = 10\n",
    "num_clusters = number_of_words / avg_words_per_cluster\n",
    "clusters = bisecting_kmeans(embeddings, num_clusters)\n",
    "\n",
    "# Print clusters\n",
    "for label, words in clusters.items():\n",
    "    print(f\"Cluster {label}: {', '.join(words)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word 'france' belongs to cluster 11.\n"
     ]
    }
   ],
   "source": [
    "# Given a word, find the cluster to which it belongs\n",
    "def find_word_cluster(word, clusters):\n",
    "    for label, words in clusters.items():\n",
    "        if word in words:\n",
    "            return label\n",
    "    return None\n",
    "\n",
    "# Example usage\n",
    "target_word = 'france'\n",
    "target_cluster = find_word_cluster(target_word, clusters)\n",
    "if target_cluster is not None:\n",
    "    print(f\"Word '{target_word}' belongs to cluster {target_cluster}.\")\n",
    "else:\n",
    "    print(f\"Word '{target_word}' does not belong to any cluster.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max intercluster distance: 108.34878412374995\n",
      "Selected Cluster 11: argentina, austria, belgium, chile, france, germany, ireland, italy, luxembourg, netherlands, portugal, spain, switzerland\n"
     ]
    }
   ],
   "source": [
    "def compute_largest_intercluster_distance(clusters, embeddings):\n",
    "    K = 1 # amplification factor, we didn't need it bigger than 1\n",
    "\n",
    "    # Calculate centroids of each cluster\n",
    "    centroids = {}\n",
    "    for label, words in clusters.items():\n",
    "        cluster_vectors = [embeddings[word] for word in words]\n",
    "        centroids[label] = K * np.mean(cluster_vectors, axis=0)\n",
    "\n",
    "    # Compute pairwise distances between centroids\n",
    "    centroid_labels = list(centroids.keys())\n",
    "    centroid_vectors = [centroids[label] for label in centroid_labels]\n",
    "    distances = manhattan_distances(centroid_vectors, centroid_vectors)\n",
    "\n",
    "    # Find the maximum distance\n",
    "    sensitivity_inter = np.max(distances)\n",
    "    \n",
    "    return distances, sensitivity_inter\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Metric DP, sensitivity = 1\n",
    "def exponential_mechanism_for_cluster(clusters, distances, selected_label, epsilon=1):\n",
    "    # Calculate the utilities for each cluster based on the negative distance to the selected cluster\n",
    "    utilities = np.array([-distances[selected_label, label] for label in clusters.keys()])\n",
    "\n",
    "    # sensitivity = np.max(distances)\n",
    "    sensitivity = 1\n",
    "\n",
    "    # Compute the probabilities for each cluster using the exponential mechanism\n",
    "    probabilities = np.exp(utilities * epsilon / (2 * sensitivity))\n",
    "    probabilities /= np.sum(probabilities)\n",
    "\n",
    "    # Select a cluster probabilistically\n",
    "    selected_cluster = np.random.choice(list(clusters.keys()), p=probabilities)\n",
    "\n",
    "    return selected_cluster\n",
    "\n",
    "\n",
    "distances_inter, sensitivity_inter = compute_largest_intercluster_distance(clusters, embeddings)\n",
    "print(f\"Max intercluster distance: {sensitivity_inter}\")\n",
    "\n",
    "selected_label = target_cluster  # The label of the cluster for which we want to select a similar cluster\n",
    "selected_cluster = exponential_mechanism_for_cluster(clusters, distances_inter, selected_label, epsilon=1)\n",
    "print(f\"Selected Cluster {selected_cluster}: {', '.join(clusters[selected_cluster])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected word: belgium\n"
     ]
    }
   ],
   "source": [
    "def compute_largest_intracluster_distance(clusters, embeddings):\n",
    "    sensitivity_intra = {}\n",
    "    for label, words in clusters.items():\n",
    "        # Get the embeddings for the words in the cluster\n",
    "        cluster_embeddings = [embeddings[word] for word in words]\n",
    "        \n",
    "        # Compute the pairwise distances within the cluster\n",
    "        if len(cluster_embeddings) > 1:\n",
    "            distances = pdist(cluster_embeddings, metric='cityblock')\n",
    "            # Find the maximum distance\n",
    "            max_distance = max(distances)\n",
    "        else:\n",
    "            # If the cluster has only one element, set the max distance to 0\n",
    "            max_distance = 0\n",
    "        \n",
    "        # Store the result in the dictionary\n",
    "        sensitivity_intra[label] = max_distance\n",
    "    \n",
    "    return sensitivity_intra\n",
    "\n",
    "\n",
    "\n",
    "def exponential_mechanism_for_word(selected_cluster_embeddings, target_word_embedding, sensitivity_intra, epsilon=1):\n",
    "    # calculate the utility for each word based on the negative\n",
    "    utilities = [-cityblock(target_word_embedding, word_embedding) for word_embedding in selected_cluster_embeddings]\n",
    "\n",
    "    # Compute the probabilities for each word using the exponential mechanism\n",
    "    probabilities = np.exp(epsilon * np.array(utilities) / (2 * sensitivity_intra))\n",
    "    probabilities /= np.sum(probabilities)\n",
    "\n",
    "    # Randomly select a word based on the probabilities\n",
    "    selected_index = np.random.choice(range(len(selected_cluster_embeddings)), p=probabilities)\n",
    "    return selected_index\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "target_word_embedding = embeddings[target_word]\n",
    "selected_cluster_embeddings = [embeddings[word] for word in clusters[selected_cluster]]\n",
    "sensitivity_intra = compute_largest_intracluster_distance(clusters, normalized_embeddings) # dict\n",
    "\n",
    "selected_index = exponential_mechanism_for_word(selected_cluster_embeddings, target_word_embedding, sensitivity_intra[selected_cluster], epsilon=1)\n",
    "selected_word = clusters[selected_cluster][selected_index]\n",
    "\n",
    "print(f\"Selected word: {selected_word}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding dimension: 300\n",
      "{'afghanistan': 'korea (republic of)', 'åland islands': 'sint maarten (dutch part)', 'albania': 'latvia', 'algeria': 'benin', 'american samoa': 'micronesia (federated states of)', 'andorra': 'belize', 'angola': 'burundi', 'anguilla': 'guatemala', 'antarctica': 'greenland', 'antigua and barbuda': 'guatemala', 'argentina': 'ireland', 'armenia': 'uzbekistan', 'aruba': 'bonaire, sint eustatius and saba', 'australia': 'australia', 'austria': 'italy', 'azerbaijan': 'azerbaijan', 'bahamas': 'martinique', 'bahrain': 'jordan', 'bangladesh': 'bangladesh', 'barbados': 'bonaire, sint eustatius and saba', 'belarus': 'tajikistan', 'belgium': 'ireland', 'belize': 'saint kitts and nevis', 'benin': 'benin', 'bermuda': 'åland islands', 'bhutan': 'tuvalu', 'bolivia (plurinational state of)': 'south sudan', 'bonaire, sint eustatius and saba': 'barbados', 'bosnia and herzegovina': 'serbia', 'botswana': 'mozambique', 'bouvet island': 'french polynesia', 'brazil': 'congo (republic of the)', 'british indian ocean territory': 'new zealand', 'brunei darussalam': 'thailand', 'bulgaria': 'finland', 'burkina faso': 'sierra leone', 'burundi': 'ethiopia', 'cabo verde': 'sierra leone', 'cambodia': 'korea (republic of)', 'cameroon': 'guinea', 'canada': \"korea (democratic people's republic of)\", 'cayman islands': 'san marino', 'central african republic': 'tanzania, united republic of', 'chad': 'gambia', 'chile': 'austria', 'china': 'cambodia', 'christmas island': 'american samoa', 'cocos (keeling) islands': 'saint helena, ascension and tristan da cunha', 'colombia': 'japan', 'comoros': 'tunisia', 'congo (republic of the)': 'south sudan', 'congo (democratic republic of the)': 'colombia', 'cook islands': 'papua new guinea', 'costa rica': 'costa rica', \"côte d'ivoire\": 'madagascar', 'croatia': 'norway', 'cuba': 'brazil', 'curaçao': 'saint barthélemy', 'cyprus': 'denmark', 'czech republic': 'uruguay', 'denmark': 'montenegro', 'djibouti': 'benin', 'dominica': 'samoa', 'dominican republic': 'denmark', 'ecuador': 'czech republic', 'egypt': 'israel', 'el salvador': 'belize', 'equatorial guinea': 'burkina faso', 'eritrea': 'togo', 'estonia': 'latvia', 'ethiopia': 'malawi', 'falkland islands (malvinas)': 'san marino', 'faroe islands': 'wallis and futuna', 'fiji': 'niue', 'finland': 'estonia', 'france': 'portugal', 'french guiana': 'saint pierre and miquelon', 'french polynesia': 'christmas island', 'french southern territories': 'congo (republic of the)', 'gabon': 'equatorial guinea', 'gambia': 'ghana', 'georgia': 'kazakhstan', 'germany': 'germany', 'ghana': 'madagascar', 'gibraltar': 'monaco', 'greece': 'slovakia', 'greenland': 'antarctica', 'grenada': 'haiti', 'guadeloupe': 'puerto rico', 'guam': 'south georgia and the south sandwich islands', 'guatemala': 'guatemala', 'guernsey': 'guernsey', 'guinea': 'algeria', 'guinea-bissau': 'guinea-bissau', 'guyana': 'nauru', 'haiti': 'honduras', 'heard island and mcdonald islands': 'cayman islands', 'vatican city state': 'cuba', 'honduras': 'curaçao', 'hong kong': 'singapore', 'hungary': 'moldova (republic of)', 'iceland': 'montenegro', 'india': 'nepal', 'indonesia': 'afghanistan', 'iran': 'iran', 'iraq': 'saudi arabia', 'ireland': 'germany', 'isle of man': 'new zealand', 'israel': 'israel', 'italy': 'austria', 'jamaica': 'honduras', 'japan': 'canada', 'jersey': 'jersey', 'jordan': 'united arab emirates', 'kazakhstan': 'uzbekistan', 'kenya': 'zambia', 'kiribati': 'palau', \"korea (democratic people's republic of)\": 'macedonia (the former yugoslav republic of)', 'korea (republic of)': 'congo (democratic republic of the)', 'kuwait': 'bahrain', 'kyrgyzstan': 'turkmenistan', \"lao people's democratic republic\": 'russian federation', 'latvia': 'paraguay', 'lebanon': 'syrian arab republic', 'lesotho': 'lesotho', 'liberia': 'eritrea', 'libya': 'syrian arab republic', 'liechtenstein': 'dominican republic', 'lithuania': 'finland', 'luxembourg': 'italy', 'macao': 'congo (republic of the)', 'macedonia (the former yugoslav republic of)': 'congo (republic of the)', 'madagascar': 'niger', 'malawi': 'zambia', 'malaysia': 'pakistan', 'maldives': 'samoa', 'mali': 'cabo verde', 'malta': 'romania', 'marshall islands': 'marshall islands', 'martinique': 'nicaragua', 'mauritania': 'equatorial guinea', 'mauritius': 'tunisia', 'mayotte': 'tokelau', 'mexico': 'macedonia (the former yugoslav republic of)', 'micronesia (federated states of)': 'sint maarten (dutch part)', 'moldova (republic of)': 'latvia', 'monaco': 'virgin islands (british)', 'mongolia': 'singapore', 'montenegro': 'estonia', 'montserrat': 'belize', 'morocco': 'qatar', 'mozambique': 'mozambique', 'myanmar': 'congo (democratic republic of the)', 'namibia': 'namibia', 'nauru': 'mayotte', 'nepal': 'nepal', 'netherlands': 'germany', 'new caledonia': 'wallis and futuna', 'new zealand': 'falkland islands (malvinas)', 'nicaragua': 'jamaica', 'niger': 'gabon', 'nigeria': 'kenya', 'niue': 'tokelau', 'norfolk island': 'norfolk island', 'northern mariana islands': 'marshall islands', 'norway': 'serbia', 'oman': 'yemen', 'pakistan': 'malaysia', 'palau': 'dominica', 'palestine, state of': 'congo (democratic republic of the)', 'panama': 'panama', 'papua new guinea': 'marshall islands', 'paraguay': 'latvia', 'peru': 'central african republic', 'philippines': 'macao', 'pitcairn': 'bouvet island', 'poland': 'latvia', 'portugal': 'netherlands', 'puerto rico': 'bonaire, sint eustatius and saba', 'qatar': 'bahrain', 'réunion': 'maldives', 'romania': 'norway', 'russian federation': 'cuba', 'rwanda': 'malawi', 'saint barthélemy': 'saint kitts and nevis', 'saint helena, ascension and tristan da cunha': 'new caledonia', 'saint kitts and nevis': 'montserrat', 'saint lucia': 'guadeloupe', 'saint martin (french part)': 'sint maarten (dutch part)', 'saint pierre and miquelon': 'bermuda', 'saint vincent and the grenadines': 'french guiana', 'samoa': 'fiji', 'san marino': 'turks and caicos islands', 'sao tome and principe': 'madagascar', 'saudi arabia': 'lebanon', 'senegal': 'mauritius', 'serbia': 'romania', 'seychelles': 'equatorial guinea', 'sierra leone': 'algeria', 'singapore': 'french southern territories', 'sint maarten (dutch part)': 'saint helena, ascension and tristan da cunha', 'slovakia': 'lithuania', 'slovenia': 'cyprus', 'solomon islands': 'christmas island', 'somalia': 'togo', 'south africa': 'colombia', 'south georgia and the south sandwich islands': 'cayman islands', 'south sudan': 'palestine, state of', 'spain': 'portugal', 'sri lanka': 'pakistan', 'sudan': 'rwanda', 'suriname': 'mayotte', 'svalbard and jan mayen': 'svalbard and jan mayen', 'swaziland': 'zambia', 'sweden': 'serbia', 'switzerland': 'switzerland', 'syrian arab republic': 'syrian arab republic', 'taiwan, province of china': 'venezuela (bolivarian republic of)', 'tajikistan': 'armenia', 'tanzania, united republic of': 'central african republic', 'thailand': 'congo (democratic republic of the)', 'timor-leste': 'palau', 'togo': 'sao tome and principe', 'tokelau': 'maldives', 'tonga': 'timor-leste', 'trinidad and tobago': 'guatemala', 'tunisia': 'djibouti', 'turkey': 'kyrgyzstan', 'turkmenistan': 'uzbekistan', 'turks and caicos islands': 'heard island and mcdonald islands', 'tuvalu': 'kiribati', 'uganda': 'zimbabwe', 'ukraine': 'uzbekistan', 'united arab emirates': 'jordan', 'united kingdom of great britain and northern ireland': 'vietnam', 'united states minor outlying islands': 'solomon islands', 'united states of america': 'south sudan', 'uruguay': 'malta', 'uzbekistan': 'kazakhstan', 'vanuatu': 'palau', 'venezuela (bolivarian republic of)': 'china', 'vietnam': 'south africa', 'virgin islands (british)': 'northern mariana islands', 'virgin islands (u.s.)': 'northern mariana islands', 'wallis and futuna': 'christmas island', 'western sahara': 'french southern territories', 'yemen': 'saudi arabia', 'zambia': 'sudan', 'zimbabwe': 'nigeria'}\n",
      "I am from bangladesh. I live in the sint maarten (dutch part).\n"
     ]
    }
   ],
   "source": [
    "# run everything here\n",
    "\n",
    "# Load the embeddings\n",
    "embeddings = load_glove_embeddings(glove_file_path='embeddings_countries.txt')\n",
    "\n",
    "# create clusters\n",
    "number_of_words = len(embeddings.keys())\n",
    "avg_words_per_cluster = 10\n",
    "num_clusters = number_of_words / avg_words_per_cluster\n",
    "clusters = bisecting_kmeans(embeddings, num_clusters)\n",
    "\n",
    "\n",
    "def replace_word(target_word, clusters, embeddings):\n",
    "\n",
    "    target_cluster = find_word_cluster(target_word, clusters)\n",
    "    # print(f\"Target Cluster {target_cluster}: {', '.join(clusters[target_cluster])}\")\n",
    "\n",
    "    # select cluster\n",
    "    distances_inter, sensitivity_inter = compute_largest_intercluster_distance(clusters, embeddings)\n",
    "    selected_label = target_cluster  # The label of the cluster for which we want to select a similar cluster\n",
    "    selected_cluster = exponential_mechanism_for_cluster(clusters, distances_inter, selected_label, epsilon=1)\n",
    "    # print(f\"Select Cluster {selected_cluster}: {', '.join(clusters[selected_cluster])}\")\n",
    "\n",
    "    # select word\n",
    "    target_word_embedding = embeddings[target_word]\n",
    "    selected_cluster_embeddings = [embeddings[word] for word in clusters[selected_cluster]]\n",
    "    sensitivity_intra = compute_largest_intracluster_distance(clusters, embeddings) # dict\n",
    "\n",
    "    selected_index = exponential_mechanism_for_word(selected_cluster_embeddings, target_word_embedding, sensitivity_intra[selected_cluster], epsilon=1)\n",
    "    selected_word = clusters[selected_cluster][selected_index]\n",
    "\n",
    "    return selected_word\n",
    "\n",
    "def get_replacement_dict(embeddings, clusters):\n",
    "    replacement_dict = {}\n",
    "    for word in embeddings.keys():\n",
    "        replacement_dict[word] = replace_word(word, clusters, embeddings)\n",
    "    return replacement_dict\n",
    "\n",
    "replacement_dict = get_replacement_dict(embeddings, clusters)\n",
    "\n",
    "print(replacement_dict)\n",
    "\n",
    "def translate_text(text, replacement_dict):\n",
    "    # Sort the keys by length in descending order\n",
    "    sorted_keys = sorted(replacement_dict.keys(), key=len, reverse=True)\n",
    "    translated_text = text\n",
    "    for key in sorted_keys:\n",
    "        # Replace occurrences of the key in the text with its value\n",
    "        translated_text = translated_text.replace(key, replacement_dict[key])\n",
    "    return translated_text\n",
    "\n",
    "text = \"I am from bangladesh. I live in the åland islands.\"\n",
    "translated_text = translate_text(text, replacement_dict)\n",
    "print(translated_text)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
